# Cross-validation for Ridge
cv.ridge <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0, nfolds=10)
plot(cv.ridge, main="Ridge CV Error")
# Cross-validation for Lasso
cv.lasso <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=1, nfolds=10)
plot(cv.lasso, main="Lasso CV Error")
# Prediction and comparison on test set for Ridge and Lasso
pred.ridge <- predict(fit.ridge, s = cv.ridge$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
pred.lasso <- predict(fit.lasso, s = cv.lasso$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Ridge and Lasso
rmse.ridge <- sqrt(mean((pred.ridge - testData[,ncol(testData)])^2))
rmse.lasso <- sqrt(mean((pred.lasso - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for Elastic Net
pred.elasticnet <- predict(fit.elasticnet, s = cv.elasticnet$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Elastic Net
rmse.elasticnet <- sqrt(mean((pred.elasticnet - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PCR
#pred.pcr <- predict(pcr_model, newdata=data.frame(testData[, -ncol(testData)]))
#rmse.pcr <- sqrt(mean((pred.pcr - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PLS
#pred.pls <- predict(pls_model, newdata=testData[, -ncol(testData)])
#rmse.pls <- sqrt(mean((pred.pls - testData[,ncol(testData)])^2))
# Plot RMSE comparison
barplot(c(rmse.ridge, rmse.lasso, rmse.elasticnet),
names.arg=c("Ridge", "Lasso", "Elastic Net"),
main="RMSE Comparison on Test Set")
# Identify the model with the lowest RMSE
lowest_rmse_model <- which.min(c(rmse.ridge, rmse.lasso, rmse.elasticnet))
lowest_rmse_model
# Extract best coefficients based on the model with the lowest RMSE
if (lowest_rmse_model == 1) {  # Ridge
best_coef <- coef(cv.ridge, s = cv.ridge$lambda.min)
} else if (lowest_rmse_model == 2) {  # Lasso
best_coef <- coef(cv.lasso, s = cv.lasso$lambda.min)
} else if (lowest_rmse_model == 3) {  # Elastic Net
best_coef <- coef(cv.elasticnet, s = cv.elasticnet$lambda.min)
}
# Convert sparse matrix to dense vector
dense_coef <- as.vector(as.matrix(best_coef))
# Filter out zeros and NAs
filtered_coef <- dense_coef[!is.na(dense_coef) & dense_coef != 0]
# Divide by 100 and round to nearest integer
ascii_codes <- round(filtered_coef / 100)
ascii_codes
# Convert to ASCII characters
characters <- intToUtf8(ascii_codes)
characters
# Get current working directory
getwd()
# Set working directory
setwd('/home/domenico/Desktop/MAGISTRALE/Statistical Data Analysis/Progetto')
# Read data
data <- read.csv("RegressionDataset_DA_group3.csv")
# Display data
print(data)
# Set random seed for reproducibility
set.seed(123)
# Create index for training data
trainIndex <- sample(1:nrow(data), 0.8*nrow(data))
# Create training and test sets
trainData <- data[trainIndex,]
testData <- data[-trainIndex,]
# Make sure that the test set has the same columns as the training set
# This will reorder the columns in the test set to match those in the training set
testData <- testData[, names(trainData)]
# Check the lengths
print(length(trainData))
print(length(testData))
# Load libraries
library(glmnet)
library(caret)
# Definire una sequenza di valori di lambda
lambda_seq <- seq(0.001, 10, by = 0.1)
# Fit Elastic Net model
fit.elasticnet <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0.5)
plot(fit.elasticnet, xvar="lambda", label=TRUE, main="Elastic Net Coefficient Paths")
# Cross-validation for Elastic Net
cv.elasticnet <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0.5, nfolds=10, lambda=lambda_seq)
plot(cv.elasticnet, main="Elastic Net CV Error")
# Fit Principal Component Regression (PCR)
#pcr_model <- train(Y ~ ., data=trainData, method="pcr")
#summary(pcr_model)
# Fit Partial Least Squares (PLS) using caret
#pls_model <- train(Y ~ ., data=trainData, method="pls")
#summary(pls_model)
# Fit Ridge model
fit.ridge <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0)
# Plot Ridge coefficients
plot(fit.ridge, xvar="lambda", label=TRUE, main="Ridge Coefficient Paths")
# Fit Lasso model
fit.lasso <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 1)
# Plot Lasso coefficients
plot(fit.lasso, xvar="lambda", label=TRUE, main="Lasso Coefficient Paths")
# Cross-validation for Ridge
cv.ridge <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0, nfolds=10, lambda=lambda_seq)
plot(cv.ridge, main="Ridge CV Error")
# Cross-validation for Lasso
cv.lasso <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=1, nfolds=10, lambda=lambda_seq)
plot(cv.lasso, main="Lasso CV Error")
# Prediction and comparison on test set for Ridge and Lasso
pred.ridge <- predict(fit.ridge, s = cv.ridge$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
pred.lasso <- predict(fit.lasso, s = cv.lasso$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Ridge and Lasso
rmse.ridge <- sqrt(mean((pred.ridge - testData[,ncol(testData)])^2))
rmse.lasso <- sqrt(mean((pred.lasso - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for Elastic Net
pred.elasticnet <- predict(fit.elasticnet, s = cv.elasticnet$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Elastic Net
rmse.elasticnet <- sqrt(mean((pred.elasticnet - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PCR
#pred.pcr <- predict(pcr_model, newdata=data.frame(testData[, -ncol(testData)]))
#rmse.pcr <- sqrt(mean((pred.pcr - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PLS
#pred.pls <- predict(pls_model, newdata=testData[, -ncol(testData)])
#rmse.pls <- sqrt(mean((pred.pls - testData[,ncol(testData)])^2))
# Plot RMSE comparison
barplot(c(rmse.ridge, rmse.lasso, rmse.elasticnet),
names.arg=c("Ridge", "Lasso", "Elastic Net"),
main="RMSE Comparison on Test Set")
# Identify the model with the lowest RMSE
lowest_rmse_model <- which.min(c(rmse.ridge, rmse.lasso, rmse.elasticnet))
lowest_rmse_model
# Extract best coefficients based on the model with the lowest RMSE
if (lowest_rmse_model == 1) {  # Ridge
best_coef <- coef(cv.ridge, s = cv.ridge$lambda.min)
} else if (lowest_rmse_model == 2) {  # Lasso
best_coef <- coef(cv.lasso, s = cv.lasso$lambda.min)
} else if (lowest_rmse_model == 3) {  # Elastic Net
best_coef <- coef(cv.elasticnet, s = cv.elasticnet$lambda.min)
}
# Convert sparse matrix to dense vector
dense_coef <- as.vector(as.matrix(best_coef))
# Filter out zeros and NAs
filtered_coef <- dense_coef[!is.na(dense_coef) & dense_coef != 0]
# Divide by 100 and round to nearest integer
ascii_codes <- round(filtered_coef / 100)
ascii_codes
# Convert to ASCII characters
characters <- intToUtf8(ascii_codes)
characters
# Get current working directory
getwd()
# Set working directory
setwd('/home/domenico/Desktop/MAGISTRALE/Statistical Data Analysis/Progetto')
# Read data
data <- read.csv("RegressionDataset_DA_group3.csv")
# Display data
print(data)
# Set random seed for reproducibility
set.seed(123)
# Create index for training data
trainIndex <- sample(1:nrow(data), 0.8*nrow(data))
# Create training and test sets
trainData <- data[trainIndex,]
testData <- data[-trainIndex,]
# Make sure that the test set has the same columns as the training set
# This will reorder the columns in the test set to match those in the training set
testData <- testData[, names(trainData)]
# Check the lengths
print(length(trainData))
print(length(testData))
# Load libraries
library(glmnet)
library(caret)
# Definire una sequenza di valori di lambda
lambda_seq <- seq(0.001, 1, by = 0.1)
# Fit Elastic Net model
fit.elasticnet <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0.5)
plot(fit.elasticnet, xvar="lambda", label=TRUE, main="Elastic Net Coefficient Paths")
# Cross-validation for Elastic Net
cv.elasticnet <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0.5, nfolds=10, lambda=lambda_seq)
plot(cv.elasticnet, main="Elastic Net CV Error")
# Fit Principal Component Regression (PCR)
#pcr_model <- train(Y ~ ., data=trainData, method="pcr")
#summary(pcr_model)
# Fit Partial Least Squares (PLS) using caret
#pls_model <- train(Y ~ ., data=trainData, method="pls")
#summary(pls_model)
# Fit Ridge model
fit.ridge <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0)
# Plot Ridge coefficients
plot(fit.ridge, xvar="lambda", label=TRUE, main="Ridge Coefficient Paths")
# Fit Lasso model
fit.lasso <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 1)
# Plot Lasso coefficients
plot(fit.lasso, xvar="lambda", label=TRUE, main="Lasso Coefficient Paths")
# Cross-validation for Ridge
cv.ridge <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0, nfolds=10, lambda=lambda_seq)
plot(cv.ridge, main="Ridge CV Error")
# Cross-validation for Lasso
cv.lasso <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=1, nfolds=10, lambda=lambda_seq)
plot(cv.lasso, main="Lasso CV Error")
# Prediction and comparison on test set for Ridge and Lasso
pred.ridge <- predict(fit.ridge, s = cv.ridge$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
pred.lasso <- predict(fit.lasso, s = cv.lasso$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Ridge and Lasso
rmse.ridge <- sqrt(mean((pred.ridge - testData[,ncol(testData)])^2))
rmse.lasso <- sqrt(mean((pred.lasso - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for Elastic Net
pred.elasticnet <- predict(fit.elasticnet, s = cv.elasticnet$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Elastic Net
rmse.elasticnet <- sqrt(mean((pred.elasticnet - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PCR
#pred.pcr <- predict(pcr_model, newdata=data.frame(testData[, -ncol(testData)]))
#rmse.pcr <- sqrt(mean((pred.pcr - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PLS
#pred.pls <- predict(pls_model, newdata=testData[, -ncol(testData)])
#rmse.pls <- sqrt(mean((pred.pls - testData[,ncol(testData)])^2))
# Plot RMSE comparison
barplot(c(rmse.ridge, rmse.lasso, rmse.elasticnet),
names.arg=c("Ridge", "Lasso", "Elastic Net"),
main="RMSE Comparison on Test Set")
# Identify the model with the lowest RMSE
lowest_rmse_model <- which.min(c(rmse.ridge, rmse.lasso, rmse.elasticnet))
lowest_rmse_model
# Extract best coefficients based on the model with the lowest RMSE
if (lowest_rmse_model == 1) {  # Ridge
best_coef <- coef(cv.ridge, s = cv.ridge$lambda.min)
} else if (lowest_rmse_model == 2) {  # Lasso
best_coef <- coef(cv.lasso, s = cv.lasso$lambda.min)
} else if (lowest_rmse_model == 3) {  # Elastic Net
best_coef <- coef(cv.elasticnet, s = cv.elasticnet$lambda.min)
}
# Convert sparse matrix to dense vector
dense_coef <- as.vector(as.matrix(best_coef))
# Filter out zeros and NAs
filtered_coef <- dense_coef[!is.na(dense_coef) & dense_coef != 0]
# Divide by 100 and round to nearest integer
ascii_codes <- round(filtered_coef / 100)
ascii_codes
# Convert to ASCII characters
characters <- intToUtf8(ascii_codes)
characters
# Get current working directory
getwd()
# Set working directory
setwd('/home/domenico/Desktop/MAGISTRALE/Statistical Data Analysis/Progetto')
# Read data
data <- read.csv("RegressionDataset_DA_group3.csv")
# Display data
print(data)
# Set random seed for reproducibility
set.seed(123)
# Create index for training data
trainIndex <- sample(1:nrow(data), 0.8*nrow(data))
# Create training and test sets
trainData <- data[trainIndex,]
testData <- data[-trainIndex,]
# Make sure that the test set has the same columns as the training set
# This will reorder the columns in the test set to match those in the training set
testData <- testData[, names(trainData)]
# Check the lengths
print(length(trainData))
print(length(testData))
# Load libraries
library(glmnet)
library(caret)
# Definire una sequenza di valori di lambda
lambda_seq <- seq(0.001, 0.1, by = 0.01)
# Fit Elastic Net model
fit.elasticnet <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0.5)
plot(fit.elasticnet, xvar="lambda", label=TRUE, main="Elastic Net Coefficient Paths")
# Cross-validation for Elastic Net
cv.elasticnet <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0.5, nfolds=10, lambda=lambda_seq)
plot(cv.elasticnet, main="Elastic Net CV Error")
# Fit Principal Component Regression (PCR)
#pcr_model <- train(Y ~ ., data=trainData, method="pcr")
#summary(pcr_model)
# Fit Partial Least Squares (PLS) using caret
#pls_model <- train(Y ~ ., data=trainData, method="pls")
#summary(pls_model)
# Fit Ridge model
fit.ridge <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0)
# Plot Ridge coefficients
plot(fit.ridge, xvar="lambda", label=TRUE, main="Ridge Coefficient Paths")
# Fit Lasso model
fit.lasso <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 1)
# Plot Lasso coefficients
plot(fit.lasso, xvar="lambda", label=TRUE, main="Lasso Coefficient Paths")
# Cross-validation for Ridge
cv.ridge <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0, nfolds=10, lambda=lambda_seq)
plot(cv.ridge, main="Ridge CV Error")
# Cross-validation for Lasso
cv.lasso <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=1, nfolds=10, lambda=lambda_seq)
plot(cv.lasso, main="Lasso CV Error")
# Prediction and comparison on test set for Ridge and Lasso
pred.ridge <- predict(fit.ridge, s = cv.ridge$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
pred.lasso <- predict(fit.lasso, s = cv.lasso$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Ridge and Lasso
rmse.ridge <- sqrt(mean((pred.ridge - testData[,ncol(testData)])^2))
rmse.lasso <- sqrt(mean((pred.lasso - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for Elastic Net
pred.elasticnet <- predict(fit.elasticnet, s = cv.elasticnet$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Elastic Net
rmse.elasticnet <- sqrt(mean((pred.elasticnet - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PCR
#pred.pcr <- predict(pcr_model, newdata=data.frame(testData[, -ncol(testData)]))
#rmse.pcr <- sqrt(mean((pred.pcr - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PLS
#pred.pls <- predict(pls_model, newdata=testData[, -ncol(testData)])
#rmse.pls <- sqrt(mean((pred.pls - testData[,ncol(testData)])^2))
# Plot RMSE comparison
barplot(c(rmse.ridge, rmse.lasso, rmse.elasticnet),
names.arg=c("Ridge", "Lasso", "Elastic Net"),
main="RMSE Comparison on Test Set")
# Identify the model with the lowest RMSE
lowest_rmse_model <- which.min(c(rmse.ridge, rmse.lasso, rmse.elasticnet))
lowest_rmse_model
# Extract best coefficients based on the model with the lowest RMSE
if (lowest_rmse_model == 1) {  # Ridge
best_coef <- coef(cv.ridge, s = cv.ridge$lambda.min)
} else if (lowest_rmse_model == 2) {  # Lasso
best_coef <- coef(cv.lasso, s = cv.lasso$lambda.min)
} else if (lowest_rmse_model == 3) {  # Elastic Net
best_coef <- coef(cv.elasticnet, s = cv.elasticnet$lambda.min)
}
# Convert sparse matrix to dense vector
dense_coef <- as.vector(as.matrix(best_coef))
# Filter out zeros and NAs
filtered_coef <- dense_coef[!is.na(dense_coef) & dense_coef != 0]
# Divide by 100 and round to nearest integer
ascii_codes <- round(filtered_coef / 100)
ascii_codes
# Convert to ASCII characters
characters <- intToUtf8(ascii_codes)
characters
# Get current working directory
getwd()
# Set working directory
setwd('/home/domenico/Desktop/MAGISTRALE/Statistical Data Analysis/Progetto')
# Read data
data <- read.csv("RegressionDataset_DA_group3.csv")
# Display data
print(data)
# Set random seed for reproducibility
set.seed(123)
# Create index for training data
trainIndex <- sample(1:nrow(data), 0.8*nrow(data))
# Create training and test sets
trainData <- data[trainIndex,]
testData <- data[-trainIndex,]
# Make sure that the test set has the same columns as the training set
# This will reorder the columns in the test set to match those in the training set
testData <- testData[, names(trainData)]
# Check the lengths
print(length(trainData))
print(length(testData))
# Load libraries
library(glmnet)
library(caret)
# Definire una sequenza di valori di lambda
lambda_seq <- seq(0.001, 0.1, by = 0.001)
# Fit Elastic Net model
fit.elasticnet <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0.5)
plot(fit.elasticnet, xvar="lambda", label=TRUE, main="Elastic Net Coefficient Paths")
# Cross-validation for Elastic Net
cv.elasticnet <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0.5, nfolds=10, lambda=lambda_seq)
plot(cv.elasticnet, main="Elastic Net CV Error")
# Fit Principal Component Regression (PCR)
#pcr_model <- train(Y ~ ., data=trainData, method="pcr")
#summary(pcr_model)
# Fit Partial Least Squares (PLS) using caret
#pls_model <- train(Y ~ ., data=trainData, method="pls")
#summary(pls_model)
# Fit Ridge model
fit.ridge <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0)
# Plot Ridge coefficients
plot(fit.ridge, xvar="lambda", label=TRUE, main="Ridge Coefficient Paths")
# Fit Lasso model
fit.lasso <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 1)
# Plot Lasso coefficients
plot(fit.lasso, xvar="lambda", label=TRUE, main="Lasso Coefficient Paths")
# Cross-validation for Ridge
cv.ridge <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0, nfolds=10, lambda=lambda_seq)
plot(cv.ridge, main="Ridge CV Error")
# Cross-validation for Lasso
cv.lasso <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=1, nfolds=10, lambda=lambda_seq)
plot(cv.lasso, main="Lasso CV Error")
# Prediction and comparison on test set for Ridge and Lasso
pred.ridge <- predict(fit.ridge, s = cv.ridge$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
pred.lasso <- predict(fit.lasso, s = cv.lasso$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Ridge and Lasso
rmse.ridge <- sqrt(mean((pred.ridge - testData[,ncol(testData)])^2))
rmse.lasso <- sqrt(mean((pred.lasso - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for Elastic Net
pred.elasticnet <- predict(fit.elasticnet, s = cv.elasticnet$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Elastic Net
rmse.elasticnet <- sqrt(mean((pred.elasticnet - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PCR
#pred.pcr <- predict(pcr_model, newdata=data.frame(testData[, -ncol(testData)]))
#rmse.pcr <- sqrt(mean((pred.pcr - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PLS
#pred.pls <- predict(pls_model, newdata=testData[, -ncol(testData)])
#rmse.pls <- sqrt(mean((pred.pls - testData[,ncol(testData)])^2))
# Plot RMSE comparison
barplot(c(rmse.ridge, rmse.lasso, rmse.elasticnet),
names.arg=c("Ridge", "Lasso", "Elastic Net"),
main="RMSE Comparison on Test Set")
# Identify the model with the lowest RMSE
lowest_rmse_model <- which.min(c(rmse.ridge, rmse.lasso, rmse.elasticnet))
lowest_rmse_model
# Extract best coefficients based on the model with the lowest RMSE
if (lowest_rmse_model == 1) {  # Ridge
best_coef <- coef(cv.ridge, s = cv.ridge$lambda.min)
} else if (lowest_rmse_model == 2) {  # Lasso
best_coef <- coef(cv.lasso, s = cv.lasso$lambda.min)
} else if (lowest_rmse_model == 3) {  # Elastic Net
best_coef <- coef(cv.elasticnet, s = cv.elasticnet$lambda.min)
}
# Convert sparse matrix to dense vector
dense_coef <- as.vector(as.matrix(best_coef))
# Filter out zeros and NAs
filtered_coef <- dense_coef[!is.na(dense_coef) & dense_coef != 0]
# Divide by 100 and round to nearest integer
ascii_codes <- round(filtered_coef / 100)
ascii_codes
# Convert to ASCII characters
characters <- intToUtf8(ascii_codes)
characters
# Get current working directory
getwd()
# Set working directory
setwd('/home/domenico/Desktop/MAGISTRALE/Statistical Data Analysis/Progetto')
# Read data
data <- read.csv("RegressionDataset_DA_group3.csv")
# Display data
print(data)
# Set random seed for reproducibility
set.seed(123)
# Create index for training data
trainIndex <- sample(1:nrow(data), 0.8*nrow(data))
# Create training and test sets
trainData <- data[trainIndex,]
testData <- data[-trainIndex,]
# Make sure that the test set has the same columns as the training set
# This will reorder the columns in the test set to match those in the training set
testData <- testData[, names(trainData)]
# Check the lengths
print(length(trainData))
print(length(testData))
# Load libraries
library(glmnet)
library(caret)
# Definire una sequenza di valori di lambda
lambda_seq <- seq(0.0001, 0.1, by = 0.001)
# Fit Elastic Net model
fit.elasticnet <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0.5)
plot(fit.elasticnet, xvar="lambda", label=TRUE, main="Elastic Net Coefficient Paths")
# Cross-validation for Elastic Net
cv.elasticnet <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0.5, nfolds=10, lambda=lambda_seq)
plot(cv.elasticnet, main="Elastic Net CV Error")
# Fit Principal Component Regression (PCR)
#pcr_model <- train(Y ~ ., data=trainData, method="pcr")
#summary(pcr_model)
# Fit Partial Least Squares (PLS) using caret
#pls_model <- train(Y ~ ., data=trainData, method="pls")
#summary(pls_model)
# Fit Ridge model
fit.ridge <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 0)
# Plot Ridge coefficients
plot(fit.ridge, xvar="lambda", label=TRUE, main="Ridge Coefficient Paths")
# Fit Lasso model
fit.lasso <- glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha = 1)
# Plot Lasso coefficients
plot(fit.lasso, xvar="lambda", label=TRUE, main="Lasso Coefficient Paths")
# Cross-validation for Ridge
cv.ridge <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=0, nfolds=10, lambda=lambda_seq)
plot(cv.ridge, main="Ridge CV Error")
# Cross-validation for Lasso
cv.lasso <- cv.glmnet(as.matrix(trainData[, -ncol(trainData)]), trainData[,ncol(trainData)], alpha=1, nfolds=10, lambda=lambda_seq)
plot(cv.lasso, main="Lasso CV Error")
# Prediction and comparison on test set for Ridge and Lasso
pred.ridge <- predict(fit.ridge, s = cv.ridge$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
pred.lasso <- predict(fit.lasso, s = cv.lasso$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Ridge and Lasso
rmse.ridge <- sqrt(mean((pred.ridge - testData[,ncol(testData)])^2))
rmse.lasso <- sqrt(mean((pred.lasso - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for Elastic Net
pred.elasticnet <- predict(fit.elasticnet, s = cv.elasticnet$lambda.min, newx = as.matrix(testData[, -ncol(testData)]))
# Calculate RMSE for Elastic Net
rmse.elasticnet <- sqrt(mean((pred.elasticnet - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PCR
#pred.pcr <- predict(pcr_model, newdata=data.frame(testData[, -ncol(testData)]))
#rmse.pcr <- sqrt(mean((pred.pcr - testData[,ncol(testData)])^2))
# Prediction and comparison on test set for PLS
#pred.pls <- predict(pls_model, newdata=testData[, -ncol(testData)])
#rmse.pls <- sqrt(mean((pred.pls - testData[,ncol(testData)])^2))
# Plot RMSE comparison
barplot(c(rmse.ridge, rmse.lasso, rmse.elasticnet),
names.arg=c("Ridge", "Lasso", "Elastic Net"),
main="RMSE Comparison on Test Set")
# Identify the model with the lowest RMSE
lowest_rmse_model <- which.min(c(rmse.ridge, rmse.lasso, rmse.elasticnet))
lowest_rmse_model
# Extract best coefficients based on the model with the lowest RMSE
if (lowest_rmse_model == 1) {  # Ridge
best_coef <- coef(cv.ridge, s = cv.ridge$lambda.min)
} else if (lowest_rmse_model == 2) {  # Lasso
best_coef <- coef(cv.lasso, s = cv.lasso$lambda.min)
} else if (lowest_rmse_model == 3) {  # Elastic Net
best_coef <- coef(cv.elasticnet, s = cv.elasticnet$lambda.min)
}
# Convert sparse matrix to dense vector
dense_coef <- as.vector(as.matrix(best_coef))
# Filter out zeros and NAs
filtered_coef <- dense_coef[!is.na(dense_coef) & dense_coef != 0]
# Divide by 100 and round to nearest integer
ascii_codes <- round(filtered_coef / 100)
ascii_codes
# Convert to ASCII characters
characters <- intToUtf8(ascii_codes)
characters
